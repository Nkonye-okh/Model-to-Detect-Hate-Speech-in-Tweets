{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31957</th>\n",
       "      <td>31958</td>\n",
       "      <td>0</td>\n",
       "      <td>ate @user isz that youuu?ðððððð...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31958</th>\n",
       "      <td>31959</td>\n",
       "      <td>0</td>\n",
       "      <td>to see nina turner on the airwaves trying to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31959</th>\n",
       "      <td>31960</td>\n",
       "      <td>0</td>\n",
       "      <td>listening to sad songs on a monday morning otw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31960</th>\n",
       "      <td>31961</td>\n",
       "      <td>1</td>\n",
       "      <td>@user #sikh #temple vandalised in in #calgary,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31961</th>\n",
       "      <td>31962</td>\n",
       "      <td>0</td>\n",
       "      <td>thank you @user for you follow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31962 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label                                              tweet\n",
       "0          1      0   @user when a father is dysfunctional and is s...\n",
       "1          2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2          3      0                                bihday your majesty\n",
       "3          4      0  #model   i love u take with u all the time in ...\n",
       "4          5      0             factsguide: society now    #motivation\n",
       "...      ...    ...                                                ...\n",
       "31957  31958      0  ate @user isz that youuu?ðððððð...\n",
       "31958  31959      0    to see nina turner on the airwaves trying to...\n",
       "31959  31960      0  listening to sad songs on a monday morning otw...\n",
       "31960  31961      1  @user #sikh #temple vandalised in in #calgary,...\n",
       "31961  31962      0                   thank you @user for you follow  \n",
       "\n",
       "[31962 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Data/train.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 31962 entries, 0 to 31961\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      31962 non-null  int64 \n",
      " 1   label   31962 non-null  int64 \n",
      " 2   tweet   31962 non-null  object\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 749.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31957</th>\n",
       "      <td>0</td>\n",
       "      <td>ate @user isz that youuu?ðððððð...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31958</th>\n",
       "      <td>0</td>\n",
       "      <td>to see nina turner on the airwaves trying to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31959</th>\n",
       "      <td>0</td>\n",
       "      <td>listening to sad songs on a monday morning otw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31960</th>\n",
       "      <td>1</td>\n",
       "      <td>@user #sikh #temple vandalised in in #calgary,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31961</th>\n",
       "      <td>0</td>\n",
       "      <td>thank you @user for you follow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31962 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                              tweet\n",
       "0          0   @user when a father is dysfunctional and is s...\n",
       "1          0  @user @user thanks for #lyft credit i can't us...\n",
       "2          0                                bihday your majesty\n",
       "3          0  #model   i love u take with u all the time in ...\n",
       "4          0             factsguide: society now    #motivation\n",
       "...      ...                                                ...\n",
       "31957      0  ate @user isz that youuu?ðððððð...\n",
       "31958      0    to see nina turner on the airwaves trying to...\n",
       "31959      0  listening to sad songs on a monday morning otw...\n",
       "31960      1  @user #sikh #temple vandalised in in #calgary,...\n",
       "31961      0                   thank you @user for you follow  \n",
       "\n",
       "[31962 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop('id', axis=1, inplace=True) #Drop ID column\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD1CAYAAABQtIIDAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAQXklEQVR4nO3df6hf9X3H8eerSedknc7qVbKbuEjNWFVYiiEL9J9uGTNr/4gFhesfNYxAilhYYX9M+0+3PwL1j1UQpmCxGKWrBttiaGs3iS2lTLS3xdVG67xUq3cJmlXn7B+6JX3vj+/7sm+u39yf8d7U+3zA4Zzv+5zP8X3gyuuezznfm1QVkiS9b7UbkCSdHQwESRJgIEiSmoEgSQIMBElSMxAkSQCsX+0Gluqiiy6qzZs3r3YbkvQb5Uc/+tF/VtXYqH2/sYGwefNmJicnV7sNSfqNkuQXp9vnlJEkCTAQJEnNQJAkAQsIhCS/neTJJP+W5EiSv+/6B5M8muT5Xl8wNObWJFNJnktyzVD96iRP9747kqTr5yR5sOtPJNn8LlyrJGkOC7lDeBv4s6r6Y2ArsCvJDuAW4HBVbQEO92eSXAFMAFcCu4A7k6zrc90F7AO29LKr63uB16vqcuB24LblX5okaTHmDYQa+FV/fH8vBewGDnT9AHBtb+8GHqiqt6vqBWAK2J5kA3BeVT1egz+xet+sMTPnegjYOXP3IElaGQt6hpBkXZKngFeBR6vqCeCSqjoG0OuL+/Bx4OWh4dNdG+/t2fVTxlTVCeAN4MIRfexLMplk8vjx4wu6QEnSwiwoEKrqZFVtBTYy+G3/qjkOH/Wbfc1Rn2vM7D7urqptVbVtbGzk9yokSUu0qC+mVdV/Jfkeg7n/V5JsqKpjPR30ah82DWwaGrYRONr1jSPqw2Omk6wHzgdeW+S1nJU23/Kt1W7hPeXFL3xitVuQ3rMW8pbRWJLf6+1zgT8HfgYcAvb0YXuAh3v7EDDRbw5dxuDh8ZM9rfRmkh39fODGWWNmznUd8Fj5T7lJ0opayB3CBuBAvyn0PuBgVX0zyePAwSR7gZeA6wGq6kiSg8AzwAng5qo62ee6CbgXOBd4pBeAe4D7k0wxuDOYOBMXJ0lauHkDoap+AnxkRP2XwM7TjNkP7B9RnwTe8fyhqt6iA0WStDr8prIkCTAQJEnNQJAkAQaCJKkZCJIkwECQJDUDQZIEGAiSpGYgSJIAA0GS1AwESRJgIEiSmoEgSQIMBElSMxAkSYCBIElqBoIkCTAQJEnNQJAkAQaCJKkZCJIkwECQJDUDQZIEGAiSpGYgSJKABQRCkk1Jvpvk2SRHkvx11/8uyX8keaqXjw+NuTXJVJLnklwzVL86ydO9744k6fo5SR7s+hNJNr8L1ypJmsNC7hBOAH9TVR8GdgA3J7mi991eVVt7+TZA75sArgR2AXcmWdfH3wXsA7b0sqvre4HXq+py4HbgtuVfmiRpMeYNhKo6VlU/7u03gWeB8TmG7AYeqKq3q+oFYArYnmQDcF5VPV5VBdwHXDs05kBvPwTsnLl7kCStjEU9Q+ipnI8AT3TpM0l+kuTLSS7o2jjw8tCw6a6N9/bs+iljquoE8AZw4WJ6kyQtz4IDIckHgK8Bn62q/2Yw/fMhYCtwDPiHmUNHDK856nONmd3DviSTSSaPHz++0NYlSQuwoEBI8n4GYfCVqvo6QFW9UlUnq+rXwJeA7X34NLBpaPhG4GjXN46onzImyXrgfOC12X1U1d1Vta2qto2NjS3sCiVJC7KQt4wC3AM8W1VfHKpvGDrsk8BPe/sQMNFvDl3G4OHxk1V1DHgzyY4+543Aw0Nj9vT2dcBj/ZxBkrRC1i/gmI8CnwKeTvJU1z4H3JBkK4OpnReBTwNU1ZEkB4FnGLyhdHNVnexxNwH3AucCj/QCg8C5P8kUgzuDieVclCRp8eYNhKr6AaPn+L89x5j9wP4R9UngqhH1t4Dr5+tFkvTu8ZvKkiTAQJAkNQNBkgQYCJKkZiBIkgADQZLUDARJEmAgSJKagSBJAgwESVIzECRJgIEgSWoGgiQJMBAkSc1AkCQBBoIkqRkIkiTAQJAkNQNBkgQYCJKkZiBIkgADQZLUDARJEmAgSJKagSBJAgwESVKbNxCSbEry3STPJjmS5K+7/sEkjyZ5vtcXDI25NclUkueSXDNUvzrJ073vjiTp+jlJHuz6E0k2vwvXKkmaw0LuEE4Af1NVHwZ2ADcnuQK4BThcVVuAw/2Z3jcBXAnsAu5Msq7PdRewD9jSy66u7wVer6rLgduB287AtUmSFmHeQKiqY1X1495+E3gWGAd2Awf6sAPAtb29G3igqt6uqheAKWB7kg3AeVX1eFUVcN+sMTPnegjYOXP3IElaGYt6htBTOR8BngAuqapjMAgN4OI+bBx4eWjYdNfGe3t2/ZQxVXUCeAO4cDG9SZKWZ8GBkOQDwNeAz1bVf8916IhazVGfa8zsHvYlmUwyefz48flaliQtwoICIcn7GYTBV6rq611+paeB6PWrXZ8GNg0N3wgc7frGEfVTxiRZD5wPvDa7j6q6u6q2VdW2sbGxhbQuSVqghbxlFOAe4Nmq+uLQrkPAnt7eAzw8VJ/oN4cuY/Dw+MmeVnozyY4+542zxsyc6zrgsX7OIElaIesXcMxHgU8BTyd5qmufA74AHEyyF3gJuB6gqo4kOQg8w+ANpZur6mSPuwm4FzgXeKQXGATO/UmmGNwZTCzvsiRJizVvIFTVDxg9xw+w8zRj9gP7R9QngatG1N+iA0WStDr8prIkCTAQJEnNQJAkAQaCJKkZCJIkwECQJDUDQZIEGAiSpGYgSJIAA0GS1AwESRJgIEiSmoEgSQIMBElSMxAkSYCBIElqBoIkCTAQJEnNQJAkAQaCJKkZCJIkwECQJDUDQZIEGAiSpGYgSJIAA0GS1OYNhCRfTvJqkp8O1f4uyX8keaqXjw/tuzXJVJLnklwzVL86ydO9744k6fo5SR7s+hNJNp/ha5QkLcBC7hDuBXaNqN9eVVt7+TZAkiuACeDKHnNnknV9/F3APmBLLzPn3Au8XlWXA7cDty3xWiRJyzBvIFTV94HXFni+3cADVfV2Vb0ATAHbk2wAzquqx6uqgPuAa4fGHOjth4CdM3cPkqSVs5xnCJ9J8pOeUrqga+PAy0PHTHdtvLdn108ZU1UngDeAC5fRlyRpCZYaCHcBHwK2AseAf+j6qN/sa476XGPeIcm+JJNJJo8fP76ohiVJc1tSIFTVK1V1sqp+DXwJ2N67poFNQ4duBI52feOI+iljkqwHzuc0U1RVdXdVbauqbWNjY0tpXZJ0GksKhH4mMOOTwMwbSIeAiX5z6DIGD4+frKpjwJtJdvTzgRuBh4fG7Ont64DH+jmDJGkFrZ/vgCRfBT4GXJRkGvg88LEkWxlM7bwIfBqgqo4kOQg8A5wAbq6qk32qmxi8sXQu8EgvAPcA9yeZYnBnMHEGrkuStEjzBkJV3TCifM8cx+8H9o+oTwJXjai/BVw/Xx+SpHeX31SWJAEGgiSpGQiSJMBAkCQ1A0GSBBgIkqRmIEiSAANBktQMBEkSYCBIkpqBIEkCDARJUjMQJEmAgSBJagaCJAkwECRJzUCQJAEGgiSpGQiSJMBAkCQ1A0GSBBgIkqRmIEiSAANBktQMBEkSYCBIktq8gZDky0leTfLTodoHkzya5PleXzC079YkU0meS3LNUP3qJE/3vjuSpOvnJHmw608k2XyGr1GStAALuUO4F9g1q3YLcLiqtgCH+zNJrgAmgCt7zJ1J1vWYu4B9wJZeZs65F3i9qi4HbgduW+rFSJKWbt5AqKrvA6/NKu8GDvT2AeDaofoDVfV2Vb0ATAHbk2wAzquqx6uqgPtmjZk510PAzpm7B0nSylnqM4RLquoYQK8v7vo48PLQcdNdG+/t2fVTxlTVCeAN4MIl9iVJWqIz/VB51G/2NUd9rjHvPHmyL8lkksnjx48vsUVJ0ihLDYRXehqIXr/a9Wlg09BxG4GjXd84on7KmCTrgfN55xQVAFV1d1Vtq6ptY2NjS2xdkjTKUgPhELCnt/cADw/VJ/rNocsYPDx+sqeV3kyyo58P3DhrzMy5rgMe6+cMkqQVtH6+A5J8FfgYcFGSaeDzwBeAg0n2Ai8B1wNU1ZEkB4FngBPAzVV1sk91E4M3ls4FHukF4B7g/iRTDO4MJs7IlUmSFmXeQKiqG06za+dpjt8P7B9RnwSuGlF/iw4USdLq8ZvKkiTAQJAkNQNBkgQYCJKkZiBIkgADQZLUDARJEmAgSJKagSBJAgwESVIzECRJgIEgSWoGgiQJMBAkSc1AkCQBBoIkqRkIkiTAQJAkNQNBkgQYCJKkZiBIkgADQZLUDARJEmAgSJKagSBJAgwESVJbViAkeTHJ00meSjLZtQ8meTTJ872+YOj4W5NMJXkuyTVD9av7PFNJ7kiS5fQlSVq8M3GH8KdVtbWqtvXnW4DDVbUFONyfSXIFMAFcCewC7kyyrsfcBewDtvSy6wz0JUlahHdjymg3cKC3DwDXDtUfqKq3q+oFYArYnmQDcF5VPV5VBdw3NEaStEKWGwgF/EuSHyXZ17VLquoYQK8v7vo48PLQ2Omujff27LokaQWtX+b4j1bV0SQXA48m+dkcx456LlBz1N95gkHo7AO49NJLF9urJGkOy7pDqKqjvX4V+AawHXilp4Ho9at9+DSwaWj4RuBo1zeOqI/6791dVduqatvY2NhyWpckzbLkQEjyO0l+d2Yb+Avgp8AhYE8ftgd4uLcPARNJzklyGYOHx0/2tNKbSXb020U3Do2RJK2Q5UwZXQJ8o98QXQ/8U1V9J8kPgYNJ9gIvAdcDVNWRJAeBZ4ATwM1VdbLPdRNwL3Au8EgvkqQVtORAqKqfA388ov5LYOdpxuwH9o+oTwJXLbUXSdLy+U1lSRJgIEiSmoEgSQIMBElSMxAkSYCBIElqBoIkCTAQJEnNQJAkAQaCJKkZCJIkwECQJDUDQZIEGAiSpLbcf0JT0m+ozbd8a7VbeE958QufWO0Wls07BEkSYCBIkpqBIEkCDARJUjMQJEmAgSBJagaCJAkwECRJzUCQJAEGgiSpGQiSJOAsCoQku5I8l2QqyS2r3Y8krTVnRSAkWQf8I/CXwBXADUmuWN2uJGltOSsCAdgOTFXVz6vqf4AHgN2r3JMkrSlny5+/HgdeHvo8DfzJ7IOS7AP29cdfJXluBXpbKy4C/nO1m5hPblvtDrQK/Nk8s/7gdDvOlkDIiFq9o1B1N3D3u9/O2pNksqq2rXYf0mz+bK6cs2XKaBrYNPR5I3B0lXqRpDXpbAmEHwJbklyW5LeACeDQKvckSWvKWTFlVFUnknwG+GdgHfDlqjqyym2tNU7F6Wzlz+YKSdU7puolSWvQ2TJlJElaZQaCJAkwECRJ7ax4qKyVleSPGHwTfJzB9z2OAoeq6tlVbUzSqvIOYY1J8rcM/jRIgCcZvPIb4Kv+UUGdzZL81Wr38F7nW0ZrTJJ/B66sqv+dVf8t4EhVbVmdzqS5JXmpqi5d7T7ey5wyWnt+Dfw+8ItZ9Q29T1o1SX5yul3AJSvZy1pkIKw9nwUOJ3me//+DgpcClwOfWa2mpHYJcA3w+qx6gH9d+XbWFgNhjamq7yT5QwZ/cnycwf9o08APq+rkqjYnwTeBD1TVU7N3JPneinezxvgMQZIE+JaRJKkZCJIkwECQJDUDQZIEGAiSpPZ/zWmLdfUQr+0AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check the number of unique values in the label.\n",
    "df['label'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "  #Replace all digits with space\n",
    "  text = re.sub(r\"[\\d-]\",'',text)\n",
    "  # Remove Unicode characters\n",
    "  text = re.sub(r'[^\\x00-\\x7F]+', '',text)\n",
    "  #Remove retweets\n",
    "  text = re.sub('user', '', text)\n",
    "  # Remove urls\n",
    "  text = re.sub(r'https?:\\/\\/[A-Za-z0-9\\.\\/]+', '', text)\n",
    "  text = re.sub(\"[^a-zA-Z]\", ' ',text)\n",
    "  # Remove mentions:\n",
    "  text = re.sub(r'@[A-Za-z0-9_]+', '', text)\n",
    "  return text\n",
    "\n",
    "df.tweet = df.tweet.apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>when a father is dysfunctional and is so se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>thanks for  lyft credit i can t use cause ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>factsguide  society now     motivation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31957</th>\n",
       "      <td>0</td>\n",
       "      <td>ate   isz that youuu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31958</th>\n",
       "      <td>0</td>\n",
       "      <td>to see nina turner on the airwaves trying to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31959</th>\n",
       "      <td>0</td>\n",
       "      <td>listening to sad songs on a monday morning otw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31960</th>\n",
       "      <td>1</td>\n",
       "      <td>sikh  temple vandalised in in  calgary   ws...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31961</th>\n",
       "      <td>0</td>\n",
       "      <td>thank you   for you follow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31962 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                              tweet\n",
       "0          0     when a father is dysfunctional and is so se...\n",
       "1          0      thanks for  lyft credit i can t use cause ...\n",
       "2          0                                bihday your majesty\n",
       "3          0   model   i love u take with u all the time in ...\n",
       "4          0             factsguide  society now     motivation\n",
       "...      ...                                                ...\n",
       "31957      0                             ate   isz that youuu  \n",
       "31958      0    to see nina turner on the airwaves trying to...\n",
       "31959      0  listening to sad songs on a monday morning otw...\n",
       "31960      1     sikh  temple vandalised in in  calgary   ws...\n",
       "31961      0                       thank you   for you follow  \n",
       "\n",
       "[31962 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_tweet = df[\"tweet\"].apply(lambda x: word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [when, a, father, is, dysfunctional, and, is, ...\n",
       "1        [thanks, for, lyft, credit, i, can, t, use, ca...\n",
       "2                                  [bihday, your, majesty]\n",
       "3        [model, i, love, u, take, with, u, all, the, t...\n",
       "4                   [factsguide, society, now, motivation]\n",
       "                               ...                        \n",
       "31957                              [ate, isz, that, youuu]\n",
       "31958    [to, see, nina, turner, on, the, airwaves, try...\n",
       "31959    [listening, to, sad, songs, on, a, monday, mor...\n",
       "31960    [sikh, temple, vandalised, in, in, calgary, ws...\n",
       "31961                       [thank, you, for, you, follow]\n",
       "Name: tweet, Length: 31962, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokenized'] = tokenized_tweet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemma(text_list):\n",
    "  lemmas = []\n",
    "  for item in text_list:\n",
    "    lemma = WordNetLemmatizer().lemmatize(item)\n",
    "    lemmas.append(lemma)\n",
    "   \n",
    "  return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized_tweet = df[\"tokenized\"].apply(lambda x: lemma(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lemmatized'] = lemmatized_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [when, a, father, is, dysfunctional, and, is, ...\n",
       "1        [thanks, for, lyft, credit, i, can, t, use, ca...\n",
       "2                                  [bihday, your, majesty]\n",
       "3        [model, i, love, u, take, with, u, all, the, t...\n",
       "4                   [factsguide, society, now, motivation]\n",
       "                               ...                        \n",
       "31957                              [ate, isz, that, youuu]\n",
       "31958    [to, see, nina, turner, on, the, airwave, tryi...\n",
       "31959    [listening, to, sad, song, on, a, monday, morn...\n",
       "31960    [sikh, temple, vandalised, in, in, calgary, ws...\n",
       "31961                       [thank, you, for, you, follow]\n",
       "Name: lemmatized, Length: 31962, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['lemmatized']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ReDI_NRW_765\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lemmatized'] = df['lemmatized'].apply(lambda x: [item for item in x if item not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>when a father is dysfunctional and is so se...</td>\n",
       "      <td>[when, a, father, is, dysfunctional, and, is, ...</td>\n",
       "      <td>[father, dysfunctional, selfish, drag, kid, dy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>thanks for  lyft credit i can t use cause ...</td>\n",
       "      <td>[thanks, for, lyft, credit, i, can, t, use, ca...</td>\n",
       "      <td>[thanks, lyft, credit, use, cause, offer, whee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>[bihday, your, majesty]</td>\n",
       "      <td>[bihday, majesty]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>model   i love u take with u all the time in ...</td>\n",
       "      <td>[model, i, love, u, take, with, u, all, the, t...</td>\n",
       "      <td>[model, love, u, take, u, time, ur]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>factsguide  society now     motivation</td>\n",
       "      <td>[factsguide, society, now, motivation]</td>\n",
       "      <td>[factsguide, society, motivation]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                              tweet  \\\n",
       "0      0     when a father is dysfunctional and is so se...   \n",
       "1      0      thanks for  lyft credit i can t use cause ...   \n",
       "2      0                                bihday your majesty   \n",
       "3      0   model   i love u take with u all the time in ...   \n",
       "4      0             factsguide  society now     motivation   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0  [when, a, father, is, dysfunctional, and, is, ...   \n",
       "1  [thanks, for, lyft, credit, i, can, t, use, ca...   \n",
       "2                            [bihday, your, majesty]   \n",
       "3  [model, i, love, u, take, with, u, all, the, t...   \n",
       "4             [factsguide, society, now, motivation]   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  [father, dysfunctional, selfish, drag, kid, dy...  \n",
       "1  [thanks, lyft, credit, use, cause, offer, whee...  \n",
       "2                                  [bihday, majesty]  \n",
       "3                [model, love, u, take, u, time, ur]  \n",
       "4                  [factsguide, society, motivation]  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label         0\n",
       "tweet         0\n",
       "tokenized     0\n",
       "lemmatized    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"tweet\", \"tokenized\"], axis = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_words(list_words):  #Detokenize tweets to be compatible with model\n",
    "  return \" \".join(list_words)\n",
    "\n",
    "\n",
    "df['sentences'] = df.lemmatized.apply(join_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>father dysfunctional selfish drag kid dysfunct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>thanks lyft credit use cause offer wheelchair ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>bihday majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>model love u take u time ur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>factsguide society motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                          sentences\n",
       "0      0  father dysfunctional selfish drag kid dysfunct...\n",
       "1      0  thanks lyft credit use cause offer wheelchair ...\n",
       "2      0                                     bihday majesty\n",
       "3      0                        model love u take u time ur\n",
       "4      0                      factsguide society motivation"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop([\"lemmatized\"], axis = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sentences = df[\"sentences\"].apply(lambda x: sent_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokenized_sentences'] = tokenized_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sentences</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>tokenized_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>father dysfunctional selfish drag kid dysfunct...</td>\n",
       "      <td>[father, dysfunctional, selfish, drag, kid, dy...</td>\n",
       "      <td>[father dysfunctional selfish drag kid dysfunc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>thanks lyft credit use cause offer wheelchair ...</td>\n",
       "      <td>[thanks, lyft, credit, use, cause, offer, whee...</td>\n",
       "      <td>[thanks lyft credit use cause offer wheelchair...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>bihday majesty</td>\n",
       "      <td>[bihday, majesty]</td>\n",
       "      <td>[bihday majesty]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>model love u take u time ur</td>\n",
       "      <td>[model, love, u, take, u, time, ur]</td>\n",
       "      <td>[model love u take u time ur]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>factsguide society motivation</td>\n",
       "      <td>[factsguide, society, motivation]</td>\n",
       "      <td>[factsguide society motivation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31957</th>\n",
       "      <td>0</td>\n",
       "      <td>ate isz youuu</td>\n",
       "      <td>[ate, isz, youuu]</td>\n",
       "      <td>[ate isz youuu]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31958</th>\n",
       "      <td>0</td>\n",
       "      <td>see nina turner airwave trying wrap mantle gen...</td>\n",
       "      <td>[see, nina, turner, airwave, trying, wrap, man...</td>\n",
       "      <td>[see nina turner airwave trying wrap mantle ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31959</th>\n",
       "      <td>0</td>\n",
       "      <td>listening sad song monday morning otw work sad</td>\n",
       "      <td>[listening, sad, song, monday, morning, otw, w...</td>\n",
       "      <td>[listening sad song monday morning otw work sad]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31960</th>\n",
       "      <td>1</td>\n",
       "      <td>sikh temple vandalised calgary wso condemns act</td>\n",
       "      <td>[sikh, temple, vandalised, calgary, wso, conde...</td>\n",
       "      <td>[sikh temple vandalised calgary wso condemns act]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31961</th>\n",
       "      <td>0</td>\n",
       "      <td>thank follow</td>\n",
       "      <td>[thank, follow]</td>\n",
       "      <td>[thank follow]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31962 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                          sentences  \\\n",
       "0          0  father dysfunctional selfish drag kid dysfunct...   \n",
       "1          0  thanks lyft credit use cause offer wheelchair ...   \n",
       "2          0                                     bihday majesty   \n",
       "3          0                        model love u take u time ur   \n",
       "4          0                      factsguide society motivation   \n",
       "...      ...                                                ...   \n",
       "31957      0                                      ate isz youuu   \n",
       "31958      0  see nina turner airwave trying wrap mantle gen...   \n",
       "31959      0     listening sad song monday morning otw work sad   \n",
       "31960      1    sikh temple vandalised calgary wso condemns act   \n",
       "31961      0                                       thank follow   \n",
       "\n",
       "                                              lemmatized  \\\n",
       "0      [father, dysfunctional, selfish, drag, kid, dy...   \n",
       "1      [thanks, lyft, credit, use, cause, offer, whee...   \n",
       "2                                      [bihday, majesty]   \n",
       "3                    [model, love, u, take, u, time, ur]   \n",
       "4                      [factsguide, society, motivation]   \n",
       "...                                                  ...   \n",
       "31957                                  [ate, isz, youuu]   \n",
       "31958  [see, nina, turner, airwave, trying, wrap, man...   \n",
       "31959  [listening, sad, song, monday, morning, otw, w...   \n",
       "31960  [sikh, temple, vandalised, calgary, wso, conde...   \n",
       "31961                                    [thank, follow]   \n",
       "\n",
       "                                     tokenized_sentences  \n",
       "0      [father dysfunctional selfish drag kid dysfunc...  \n",
       "1      [thanks lyft credit use cause offer wheelchair...  \n",
       "2                                       [bihday majesty]  \n",
       "3                          [model love u take u time ur]  \n",
       "4                        [factsguide society motivation]  \n",
       "...                                                  ...  \n",
       "31957                                    [ate isz youuu]  \n",
       "31958  [see nina turner airwave trying wrap mantle ge...  \n",
       "31959   [listening sad song monday morning otw work sad]  \n",
       "31960  [sikh temple vandalised calgary wso condemns act]  \n",
       "31961                                     [thank follow]  \n",
       "\n",
       "[31962 rows x 4 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Data/cleaned_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cf68b5f3d8f23fabb64fa988f1c08fc25a98e529a37082d4f0f1b429c1758919"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
