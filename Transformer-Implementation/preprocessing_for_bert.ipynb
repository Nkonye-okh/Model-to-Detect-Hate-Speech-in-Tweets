{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sentences</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>tokenized_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>father dysfunctional selfish drag kid dysfunct...</td>\n",
       "      <td>['father', 'dysfunctional', 'selfish', 'drag',...</td>\n",
       "      <td>['father dysfunctional selfish drag kid dysfun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>thanks lyft credit use cause offer wheelchair ...</td>\n",
       "      <td>['thanks', 'lyft', 'credit', 'use', 'cause', '...</td>\n",
       "      <td>['thanks lyft credit use cause offer wheelchai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>bihday majesty</td>\n",
       "      <td>['bihday', 'majesty']</td>\n",
       "      <td>['bihday majesty']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>model love u take u time ur</td>\n",
       "      <td>['model', 'love', 'u', 'take', 'u', 'time', 'ur']</td>\n",
       "      <td>['model love u take u time ur']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>factsguide society motivation</td>\n",
       "      <td>['factsguide', 'society', 'motivation']</td>\n",
       "      <td>['factsguide society motivation']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                          sentences  \\\n",
       "0      0  father dysfunctional selfish drag kid dysfunct...   \n",
       "1      0  thanks lyft credit use cause offer wheelchair ...   \n",
       "2      0                                     bihday majesty   \n",
       "3      0                        model love u take u time ur   \n",
       "4      0                      factsguide society motivation   \n",
       "\n",
       "                                          lemmatized  \\\n",
       "0  ['father', 'dysfunctional', 'selfish', 'drag',...   \n",
       "1  ['thanks', 'lyft', 'credit', 'use', 'cause', '...   \n",
       "2                              ['bihday', 'majesty']   \n",
       "3  ['model', 'love', 'u', 'take', 'u', 'time', 'ur']   \n",
       "4            ['factsguide', 'society', 'motivation']   \n",
       "\n",
       "                                 tokenized_sentences  \n",
       "0  ['father dysfunctional selfish drag kid dysfun...  \n",
       "1  ['thanks lyft credit use cause offer wheelchai...  \n",
       "2                                 ['bihday majesty']  \n",
       "3                    ['model love u take u time ur']  \n",
       "4                  ['factsguide society motivation']  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Data/cleaned_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    29720\n",
       "1     2242\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing with a `BertTokenizer`\n",
    "\n",
    "Tweets will be tokenized to create two input tensors; input IDs, and attention mask.\n",
    "\n",
    "Tensors will be contained within two numpy arrays, which will be of dimensions `len(df) * 512` - the `512` is the sequence length of tokenized sequences for BERT, and `len(df)` the number of samples in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31962, 512)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_len = 512\n",
    "num_samples = len(df)\n",
    "\n",
    "num_samples, seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize - returning Numpy tensors\n",
    "tokens = tokenizer(df['tokenized_sentences'].to_list(), max_length=seq_len, truncation=True,\n",
    "                   padding='max_length', add_special_tokens=True,\n",
    "                   return_tensors='np')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[101, 164, 112, ...,   0,   0,   0],\n",
       "       [101, 164, 112, ...,   0,   0,   0],\n",
       "       [101, 164, 112, ...,   0,   0,   0],\n",
       "       ...,\n",
       "       [101, 164, 112, ...,   0,   0,   0],\n",
       "       [101, 164, 112, ...,   0,   0,   0],\n",
       "       [101, 164, 112, ...,   0,   0,   0]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens['attention_mask']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save keys generated by tokenizer as Numpy binary files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tweets_xids.npy', 'wb') as f:\n",
    "    np.save(f, tokens['input_ids'])\n",
    "\n",
    "with open('tweets_xmask.npy', 'wb') as f:\n",
    "    np.save(f, tokens['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the in-memory arrays to free up memory.\n",
    "del tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 0, ..., 0, 1, 0], dtype=int64), (31962,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = df['label'].values\n",
    "arr, arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.max()+1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract label values and *one-hot* encode them into another numpy array, which will have the dimensions `len(df) * number of label classes`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first extract label column\n",
    "arr = df['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31962, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Then initialize a zero array\n",
    "labels = np.zeros((num_samples, arr.max()+1)) # arr.max()+1 because there are two unique labels and we need our labels array to have one column for each label\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the current values in our `arr` of *\\[0, 1]* to place `1` values in the correct positions of the zeros-only array:\n",
    "labels[np.arange(num_samples), arr] = 1\n",
    "\n",
    "labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save one-hot encoded array to a Numpy binary file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('twitter-labels.npy', 'wb') as f:\n",
    "    np.save(f, labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cf68b5f3d8f23fabb64fa988f1c08fc25a98e529a37082d4f0f1b429c1758919"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
