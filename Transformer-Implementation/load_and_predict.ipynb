{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.load_model('hate_detection_model')\n",
    "\n",
    "# view model architecture to confirm we have save and loaded correctly\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "\n",
    "def prep_data(text):\n",
    "    tokens = tokenizer.encode_plus(text, max_length=512,\n",
    "                                   truncation=True, padding='max_length',\n",
    "                                   add_special_tokens=True, return_token_type_ids=False,\n",
    "                                   return_tensors='tf')\n",
    "    # tokenizer returns int32 tensors, we need to return float64, so we use tf.cast\n",
    "    return {'input_ids': tf.cast(tokens['input_ids'], tf.float64),\n",
    "            'attention_mask': tf.cast(tokens['attention_mask'], tf.float64)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = model.predict(prep_data(\"stinken folks\"))[0]\n",
    "\n",
    "probs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# so we can see full phrase\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "dfa = pd.read_table('Data/Tweet_test - Sheet1.tsv')\n",
    "dfa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "  #Replace all digits with space\n",
    "  text = re.sub(r\"[\\d-]\",'',text)\n",
    "  # Remove Unicode characters\n",
    "  text = re.sub(r'[^\\x00-\\x7F]+', '',text)\n",
    "  #Remove retweets\n",
    "  text = re.sub('user', '', text)\n",
    "  # Remove urls\n",
    "  text = re.sub(r'https?:\\/\\/[A-Za-z0-9\\.\\/]+', '', text)\n",
    "  text = re.sub(\"[^a-zA-Z]\", ' ',text)\n",
    "  # Remove mentions:\n",
    "  text = re.sub(r'@[A-Za-z0-9_]+', '', text)\n",
    "  return text\n",
    "\n",
    "dfa.Tweets = dfa.Tweets.apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa['Label'] = None\n",
    "\n",
    "for i, row in dfa.iterrows():\n",
    "    # get token tensors\n",
    "    tokens = prep_data(row['Tweets'])\n",
    "    # get probabilities\n",
    "    probs = model.predict(tokens)\n",
    "    # find argmax for winning class\n",
    "    pred = np.argmax(probs)\n",
    "    # add to dataframe\n",
    "    dfa.at[i, 'Label'] = pred\n",
    "\n",
    "dfa.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa.to_csv('Data/predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft = pd.read_csv('Data/Test_label.csv') # Gold data\n",
    "dft.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft.tail(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa.tail(15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cf68b5f3d8f23fabb64fa988f1c08fc25a98e529a37082d4f0f1b429c1758919"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
